{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advent of code 2020\n",
    "\n",
    "Daily coding challenge and problem solving before Christmas ! \n",
    "\n",
    "All problems are available here : https://adventofcode.com/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import re\n",
    "data_folder = './data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mul of 2 number that add to 2020:  982464\n",
      "Mul of 3 number that add to 2020:  162292410\n",
      "Mul of 3 number that add to 2020:  162292410\n",
      "Mul of 3 number that add to 2020:  162292410\n"
     ]
    }
   ],
   "source": [
    "text_file = open(data_folder + \"input1.txt\", \"r\")\n",
    "lines = text_file.readlines()\n",
    "\n",
    "values = [ int(l.strip()) for l in lines ]\n",
    "\n",
    "# Task 1\n",
    "for idx, v1 in enumerate(values):\n",
    "    for v2 in values[idx:]:\n",
    "        if v1 + v2 == 2020:\n",
    "            print(\"Mul of 2 number that add to 2020: \",v1*v2)\n",
    "\n",
    "# Task 2\n",
    "for idx1, v1 in enumerate(values):\n",
    "    for idx2, v2 in enumerate(values[idx1:]):\n",
    "        for idx3, v3 in enumerate(values[idx2:]):\n",
    "            if v1 + v2 + v3 == 2020:\n",
    "                print(\"Mul of 3 number that add to 2020: \", v1 * v2 * v3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = open(data_folder + \"input2.txt\", \"r\")\n",
    "lines = input_file.readlines()  \n",
    "\n",
    "entries = [l.strip() for l in lines]\n",
    "\n",
    "def parse_entry(e):\n",
    "    s1 = e.split(':')\n",
    "    pwd = s1[1].strip()\n",
    "    s2 = s1[0].split(' ')\n",
    "    char = s2[1].strip()\n",
    "    s3 = s2[0].split('-')\n",
    "    lower_bound, upper_bound = int(s3[0]),int(s3[1])\n",
    "    return char, lower_bound, upper_bound, pwd\n",
    "\n",
    "def check_validity_nb(char, lb, ub, pwd):\n",
    "    count = pwd.count(char)\n",
    "    return count >= lb and count <= ub \n",
    "\n",
    "def check_validity_pos(char, p1, p2, pwd):\n",
    "    cp1 = pwd[p1]\n",
    "    cp2 = pwd[p2]\n",
    "    return (cp1 == char and cp2 != char) or (cp1 != char and cp2 == char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 517 valid pwds for Task 1\n"
     ]
    }
   ],
   "source": [
    "# Task 1 \n",
    "valid_entries = 0 \n",
    "for e in entries:\n",
    "    char, lb, ub, pwd = parse_entry(e)\n",
    "    if(check_validity_nb(char,lb,ub,pwd)):\n",
    "        valid_entries += 1\n",
    "print(f\"There are {valid_entries} valid pwds for Task 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 284 valid pwds for Task 2\n"
     ]
    }
   ],
   "source": [
    "# Task 2 \n",
    "valid_entries = 0 \n",
    "for e in entries:\n",
    "    char, p1, p2, pwd = parse_entry(e)\n",
    "    if(check_validity_pos(char,p1-1,p2-1,pwd)):\n",
    "        valid_entries += 1\n",
    "print(f\"There are {valid_entries} valid pwds for Task 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could've used regex instead of ugly splits here ! \n",
    "\n",
    "## Day 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 323\n"
     ]
    }
   ],
   "source": [
    "with open(data_folder + \"input3.txt\", \"r\") as f:\n",
    "    lines = f.readlines()  \n",
    "\n",
    "    forest = [l.strip() for l in lines]\n",
    "    width = len(forest[0])\n",
    "    height = len(forest)\n",
    "    print(width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With such a slope we encounter 205 trees\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 1 \n",
    "def find_nb_trees_for_slope(slope):\n",
    "    slope_x, slope_y = slope\n",
    "    pos_x, pos_y = 0, 0\n",
    "    nb_trees = 0 \n",
    "    for r in range(int(height/slope_y)):\n",
    "        if forest[pos_y][pos_x] == '#':\n",
    "            nb_trees += 1 \n",
    "        pos_x = (pos_x + slope_x) % width\n",
    "        pos_y += slope_y \n",
    "    print(f\"With such a slope we encounter {nb_trees} trees\")\n",
    "    return nb_trees\n",
    "    \n",
    "find_nb_trees_for_slope((3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With such a slope we encounter 87 trees\n",
      "With such a slope we encounter 205 trees\n",
      "With such a slope we encounter 85 trees\n",
      "With such a slope we encounter 79 trees\n",
      "With such a slope we encounter 33 trees\n",
      "If we multiply together the trees encountered on each slope we get 3952146825\n"
     ]
    }
   ],
   "source": [
    "# Task 2 \n",
    "slopes = [(1,1),(3,1),(5,1),(7,1),(1,2)]\n",
    "nb_trees = np.zeros(len(slopes))\n",
    "\n",
    "for idx, s in enumerate(slopes): \n",
    "    nb_trees[idx] = find_nb_trees_for_slope(s)\n",
    "result = np.prod(nb_trees)\n",
    "print(f\"If we multiply together the trees encountered on each slope we get {int(result)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_folder + \"input4.txt\", \"r\") as f:\n",
    "    lines = f.readlines()  \n",
    "    \n",
    "    passports = np.array([l.strip() for l in lines])\n",
    "    blank_lines = np.where(passports == '')\n",
    "    pp_array = np.split(passports, np.array(blank_lines)[0],axis=0)\n",
    "    passports_strings = np.array([' '.join(pl).strip() for pl in pp_array])\n",
    "\n",
    "fields = ['byr', 'iyr', 'eyr', 'hgt', 'hcl', 'ecl', 'pid', 'cid']\n",
    "fields_that_matter = ['byr', 'iyr', 'eyr', 'hgt', 'hcl', 'ecl', 'pid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 208 valid passports in the database\n"
     ]
    }
   ],
   "source": [
    "# Task 1 \n",
    "\n",
    "def is_valid_password(pwd, required_fields):\n",
    "    return np.array(list(map(lambda f : pwd.find(f) >= 0, required_fields))).prod(), pwd \n",
    "        \n",
    "\n",
    "valid_pwds_idx = np.array([is_valid_password(p, fields_that_matter)[0] for p in passports_strings])\n",
    "\n",
    "print(f\"There are {valid_pwds_idx.sum()} valid passports in the database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 167 valid passports according to new policies\n"
     ]
    }
   ],
   "source": [
    "# Task 2 \n",
    "def valid_byr(m):\n",
    "    byr = int(m.group(2))\n",
    "    return 1920 <= byr and 2002 >= byr\n",
    "\n",
    "def valid_iyr(m):\n",
    "    iyr = int(m.group(2))\n",
    "    return 2010 <= iyr and 2020 >= iyr\n",
    "\n",
    "def valid_eyr(m):\n",
    "    eyr = int(m.group(2))\n",
    "    return 2020 <= eyr and 2030 >= eyr\n",
    "\n",
    "def valid_hgt(m):\n",
    "    hgt, unit = int(m.group(2)), m.group(3)\n",
    "    return 150 <= hgt and hgt <= 193 if unit == 'cm' else 59 <= hgt and hgt <= 76\n",
    "\n",
    "def valid_ecl(m):\n",
    "    ecl = m.group(2)\n",
    "    ecl_vals = ['amb', 'blu', 'brn', 'gry', 'grn', 'hzl', 'oth']\n",
    "    return ecl in ecl_vals\n",
    "\n",
    "def valid_pid(m):\n",
    "    pid = m.group(2)\n",
    "    return len(pid) == 9 \n",
    "\n",
    "switch = {\n",
    "  'byr': lambda x: valid_byr(x),\n",
    "  'iyr': lambda x: valid_iyr(x),\n",
    "  'eyr': lambda x: valid_eyr(x),\n",
    "  'hgt': lambda x: valid_hgt(x),  \n",
    "  'ecl': lambda x: valid_ecl(x),\n",
    "  'pid': lambda x: valid_pid(x),\n",
    "  'hcl': lambda x: True,\n",
    "  None : lambda x: False\n",
    "}\n",
    "    \n",
    "re_s = ['(byr):([0-9]{4})', '(iyr):([0-9]{4})', '(eyr):([0-9]{4})', '(hgt):([0-9]{2,3})(cm|in)', '(ecl):([a-z]{3})', '(hcl):(#[a-z0-9]{6})', '(pid):([0-9]*)']\n",
    "valid_fields_pwds = passports_strings[[val == 1 for val in valid_pwds_idx]]\n",
    "tot = 0 \n",
    "for pwd in valid_fields_pwds:\n",
    "    array = np.array([False if re.search(r, pwd) == None \n",
    "                      else switch[re.search(r, pwd).group(1)](re.search(r, pwd)) for r in re_s])\n",
    "    tot += array.prod()\n",
    "print(f\"Found {tot} valid passports according to new policies\")\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_folder + \"input5.txt\", \"r\") as f:\n",
    "    lines = f.readlines()  \n",
    "    boarding_passes = np.array([l.strip() for l in lines])\n",
    "\n",
    "    \n",
    "def convert_to_binary(bp):\n",
    "    row_b = bp[:7].replace('B','1').replace('F', '0')\n",
    "    column_b = bp[7:].replace('R','1').replace('L', '0')\n",
    "    return row_b, column_b\n",
    "\n",
    "def get_row_column_seat(row_b, col_b):\n",
    "    row = int(row_b,2)\n",
    "    col = int(col_b,2)\n",
    "    \n",
    "    return row, col, row * 8 + col\n",
    "\n",
    "def get_position_from_boarding_pass(bp):\n",
    "    row_b, col_b = convert_to_binary(bp)\n",
    "    return get_row_column_seat(row_b, col_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max seat number of plane is 994\n",
      "Min seat number of plane is 61\n"
     ]
    }
   ],
   "source": [
    "# Task 1 \n",
    "\n",
    "max_seat_id = 0\n",
    "min_seat_id = 100000\n",
    "for bp in boarding_passes:\n",
    "    _, _, seat_id = get_position_from_boarding_pass(bp)\n",
    "    if seat_id > max_seat_id: \n",
    "        max_seat_id = seat_id\n",
    "    if seat_id < min_seat_id:\n",
    "        min_seat_id = seat_id\n",
    "print(f\"Max seat number of plane is {max_seat_id}\")\n",
    "print(f\"Min seat number of plane is {min_seat_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your seat number is 741\n"
     ]
    }
   ],
   "source": [
    "# Task 2 \n",
    "\n",
    "sl = []\n",
    "for bp in boarding_passes:\n",
    "    _, _, seat_id = get_position_from_boarding_pass(bp)\n",
    "    sl.append(seat_id)\n",
    "sorted_seats = np.sort(sl)\n",
    "all_seats = range(min_seat_id,max_seat_id+1)\n",
    "\n",
    "empty_seats_list = list(set(all_seats) ^ set(sorted_seats))\n",
    "\n",
    "print(f\"Your seat number is {empty_seats_list[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "with open(data_folder + 'input6.txt', 'r') as f :\n",
    "    lines = f.readlines()\n",
    "    answers = np.array([l.strip() for l in lines])\n",
    "    \n",
    "    blank_lines = np.where(answers == '')\n",
    "    groups_arrays = np.split(answers,blank_lines[0])\n",
    "    groups_arrays = [np.delete(ga, np.where(ga == '')) for ga in groups_arrays]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 6170 positive answers has been given by anyone in their groups\n"
     ]
    }
   ],
   "source": [
    "# Task 1 \n",
    "\n",
    "groups_answers = [(''.join(ga), len(ga)) for ga in groups_arrays]\n",
    "\n",
    "groups_answer_unique = [''.join(set(ga)) for ga, _ in groups_answers]\n",
    "\n",
    "total_unique_answers = np.sum([len(ans) for ans in groups_answer_unique])\n",
    "\n",
    "print(f\"A total of {total_unique_answers} positive answers has been given by anyone in their groups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 2947 positive answers has been given by everyone in there groups \n"
     ]
    }
   ],
   "source": [
    "# Task 2 \n",
    "alphabet = string.ascii_lowercase\n",
    "\n",
    "def get_answered_by_everyone(answer, group_size):\n",
    "    answered = ''\n",
    "    for letter in alphabet: \n",
    "        if answer.count(letter) == group_size:\n",
    "            answered += letter\n",
    "    return answered\n",
    "\n",
    "total_universal_answers = np.sum([len(get_answered_by_everyone(ans, count)) for ans, count in groups_answers])\n",
    "\n",
    "print(f\"A total of {total_universal_answers} positive answers has been given by everyone in there groups \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(data_folder + \"input7.txt\",'r') as f:\n",
    "    lines = f.readlines()\n",
    "    rules = [l.strip() for l in lines]\n",
    "\n",
    "def create_rules_dict(rules):\n",
    "    re_color = r'([a-z\\s]+) bags contain'\n",
    "    re_bags = r'(\\d) (.*?) bags?'\n",
    "    rules_dict = {}\n",
    "    for r in rules:\n",
    "        temp_dict = {}\n",
    "        bags = re.findall(re_bags, r)\n",
    "        if len(bags) > 0:\n",
    "            for b in bags:\n",
    "                temp_dict[b[1]] = int(b[0]) \n",
    "        else: \n",
    "            temp_dict['other'] = 0\n",
    "        match = re.search(re_color, r)\n",
    "        rules_dict[match.group(1)] = temp_dict\n",
    "    return rules_dict\n",
    "\n",
    "rules_dict = create_rules_dict(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 229 different colors that can eventually contain our bag ! \n"
     ]
    }
   ],
   "source": [
    "# Task 1 \n",
    "\n",
    "all_colors = ['shiny gold']\n",
    "\n",
    "previous_size = 1\n",
    "new_size = 0\n",
    "\n",
    "while previous_size != new_size:\n",
    "    previous_size = new_size\n",
    "    for color in all_colors:\n",
    "        for r in rules_dict:\n",
    "            rl = rules_dict[r]\n",
    "            if color in rl.keys() and r not in all_colors:\n",
    "                all_colors.append(r)\n",
    "    new_size = len(all_colors)\n",
    "\n",
    "all_colors.remove('shiny gold')\n",
    "print(f\"There are {len(all_colors)} different colors that can eventually contain our bag ! \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shiny gold bag contains 6683 different bags.\n"
     ]
    }
   ],
   "source": [
    "# Task 2 \n",
    "\n",
    "def get_req_nb_bags(color, init_val = 0):\n",
    "    nb_bags = init_val\n",
    "    \n",
    "    for r in rules_dict[color]:\n",
    "        if r == 'other':\n",
    "            nb_bags = 1\n",
    "        else:\n",
    "            nb_bags += rules_dict[color][r] * get_req_nb_bags(r, 1)\n",
    "    return nb_bags\n",
    "\n",
    "print(f'The shiny gold bag contains {get_req_nb_bags(\"shiny gold\")} different bags.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_folder + 'input8.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    instructions = [l.strip() for l in lines]\n",
    "\n",
    "def parse_data(data):\n",
    "    regex = r'([a-z]{3}) ([0-9+-]*)'\n",
    "    ret_data = []\n",
    "    for d in data:\n",
    "        match = re.match(regex, d)\n",
    "        ret_data.append((match.group(1), int(match.group(2))))\n",
    "    return ret_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right before starting the infinite loop by visiting again step 118 the acc value is 1684\n"
     ]
    }
   ],
   "source": [
    "# Task 1 \n",
    "\n",
    "instruction_switch = {\n",
    "    'acc' : lambda value, pointer, acc : (pointer + 1, acc + value),\n",
    "    'jmp' : lambda value, pointer, acc : (pointer + value, acc),\n",
    "    'nop' : lambda value, pointer, acc : (pointer + 1, acc)\n",
    "}\n",
    "\n",
    "parsed_instructions = parse_data(instructions)\n",
    "def get_acc_before_inf_loop(data, print_termination = False):\n",
    "    pointer = 0 \n",
    "    acc =  0 \n",
    "    visited_steps = []\n",
    "\n",
    "    while pointer not in visited_steps and pointer < len(data):\n",
    "        i, v = data[pointer]\n",
    "        visited_steps.append(pointer)\n",
    "        pointer, acc = instruction_switch[i](v, pointer, acc)\n",
    "    \n",
    "    if pointer >= len(data):\n",
    "        print(f\"Value of acc when the program terminates is {acc}\")\n",
    "    else :\n",
    "        if not print_termination:\n",
    "            print(f'Right before starting the infinite loop by visiting again step {pointer} the acc value is {acc}')\n",
    "    \n",
    "\n",
    "get_acc_before_inf_loop(parsed_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of acc when the program terminates is 2188\n"
     ]
    }
   ],
   "source": [
    "# Task 2\n",
    "\n",
    "for idx, (inst, value) in enumerate(parsed_instructions):\n",
    "    compute = False\n",
    "    p_i_copy = parsed_instructions.copy()\n",
    "    if inst == 'nop':\n",
    "        compute = True\n",
    "        p_i_copy[idx] = ('jmp', value)\n",
    "    if inst == 'jmp':\n",
    "        compute = True\n",
    "        p_i_copy[idx] = ('nop', value)\n",
    "    if compute: \n",
    "        get_acc_before_inf_loop(p_i_copy, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 9 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
